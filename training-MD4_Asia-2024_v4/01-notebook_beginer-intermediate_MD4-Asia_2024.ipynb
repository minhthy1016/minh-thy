{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad7f669-cf9c-49b2-b085-ae84a008700d",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "![header](img/Copernicus_header.jpg)\n",
    "\n",
    "<h1 style=\"text-align: center;\"><span style=\"color: #22689B;\"><strong>Copernicus Marine Service Training Workshops</strong></span></h1>\n",
    "<p>&nbsp;</p>\n",
    "<h2 style=\"text-align: center;\"><span style=\"color: #22689B;\">Marine Data 4 Asia</span></h2>\n",
    "<p>&nbsp;</p>\n",
    "<h2 style=\"text-align: center;\"><span style=\"color: #22689B;\"><strong>Analysis of El Niño-Southern Oscillation (ENSO)</strong></span></h2>\n",
    "\n",
    "***\n",
    "\n",
    "# <span style=\"color: #22689B;\">**Table of Contents:**</span>\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Plot NINO3.4 index](#Plot_NINO_index)\n",
    "1. [Data downloading with Coprnicus Marine Client](#Data_downloading)\n",
    "1. [Plotting maps of anomalies](#Maps_of_anomalies)\n",
    "1. [Plotting El Niño and La Niña patterns](#Plotting_patterns)\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed3db6-4893-44f4-a97e-05555c1a10c3",
   "metadata": {},
   "source": [
    "<a id=\"Introduction\"></a>\n",
    "# <span style=\"color: #22689B;\">**1. Introduction**</span>\n",
    "\n",
    "The El Niño Southern Oscillation is a large-scale warming event in the equatorial Pacific Ocean.\n",
    "\n",
    "In the Neutral state, which represents normal conditions, trade winds blow east to west across the tropical Pacific Ocean surface. This movement brings warm moist air and warmer surface waters toward the western Pacific while maintaining cooler conditions in the central Pacific Ocean. The thermocline is deeper in the west than in the east.\n",
    "\n",
    "During a La Niña event, the intensification of trade winds confines the pool of warmer water to the far western tropical Pacific, resulting in above-average sea surface temperatures (SSTs) north of Australia. Meanwhile, SSTs across the central and eastern tropical Pacific Ocean become cooler than usual, and the thermocline moves closer to the surface due to strengthened upwelling, drawing cool waters from the deep ocean.\n",
    "\n",
    "In an El Niño event, trade winds weaken or may even reverse, allowing the area of warmer-than-normal water to extend into the central and eastern tropical Pacific Ocean. Sea surface temperatures around northern Australia are cooler than normal, and convection shifts away from Australia, moving eastward toward the central tropical Pacific Ocean.\n",
    "\n",
    "<p><img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"img/ENSO_phases.png\" alt=\"\" /></p>\n",
    "<p style=\"text-align: center;\"><em><a href=\"https://link.springer.com/chapter/10.1007/978-3-031-17825-2_4\">The three phases (Neutral, El Niño, and La Niña) of the El Niño–Southern Oscillation (ENSO) from Chowdhury (2022).</a></em></p>\n",
    "\n",
    "These processes interact and mutually reinforce each other, leading to a sustained alteration of atmospheric circulation with global impacts, including the intensification of the East Asian and western North Pacific monsoons and impacts on the Asian-Pacific climate (Zhou et al, 2014).\n",
    "\n",
    "### Bibliography\n",
    "\n",
    "* Chowdhury, M. R. (2022). Overview of Weather, ENSO, and Climate Scale. In Seasonal Flood Forecasts and Warning Response Opportunities: ENSO Applications in Bangladesh (pp. 59-74). Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-17825-2_4.\n",
    "\n",
    "* Wang, C., Deser, C., Yu, J. Y., DiNezio, P., & Clement, A. (2017). El Niño and southern oscillation (ENSO): a review. Coral reefs of the eastern tropical Pacific: Persistence and loss in a dynamic environment, 85-106. https://doi.org/10.1007/978-94-017-7499-4_4.\n",
    "\n",
    "* Zhou, T., Wu, B., & Dong, L. (2014). Advances in research of ENSO changes and the associated impacts on Asian-Pacific climate. Asia-Pacific Journal of Atmospheric Sciences, 50, 405-422.  https://doi.org/10.1007/s13143-014-0043-4.\n",
    "\n",
    "\n",
    "### Setup\n",
    "First of all, the python interpreter must import all the necessary tools and libraries from the Jupyter Notebook Ecosystem. The following cell compiles all the libraries that will be used during the tutorial:\n",
    "\n",
    "**General Note**: Execute each cell through the <button class=\"btn btn-default btn-xs\"><i class=\"icon-play fa fa-play\"></i></button> button from the top MENU (or keyboard shortcut `Shift` + `Enter`).<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b066d8e-aa87-4f28-a31e-9b92df4b374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requested libraries\n",
    "\n",
    "# To avoid warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import copernicus_marine_client as cmc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c0fba-d995-4041-87f9-8decfc6a8130",
   "metadata": {},
   "source": [
    "Below, you find the description and documentation of the libraries used:\n",
    "\n",
    "| Module name | Description |\n",
    "| :---: | :---|\n",
    "| **numpy** | [NumPy](https://numpy.org/) is the fundamental package for scientific computing with Python and for managing ND-arrays |\n",
    "| **xarray** | [Xarray](http://xarray.pydata.org/en/stable/) introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. |\n",
    "| **pandas** | [Pandas](https://pandas.pydata.org/docs/) is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive |\n",
    "| **matplotlib** |[Matplotlib](https://matplotlib.org/) is a Python 2D plotting library which produces publication quality figures |\n",
    "| **cartopy** |[Cartopy](https://scitools.org.uk/cartopy/docs/latest/) is a library for plotting maps and geospatial data analyses in Python. |\n",
    "| **copernicus_marine_client** | [Copernicus marine toolbox](https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction) is a free and easy-to-use tool that interoperates with the Copernicus Marine Data Store with the aim of covering any use case, from retrieval of metadata to a complete dataset, or just a sub-part, for any type of product: numerical models, satellite and/or in-situ observations.\n",
    "\n",
    "Throughout this tutorial, various functions from these libraries will be utilized. In each instance, the application of every function will be elucidated, accompanied by links to the pertinent documentation. Special emphasis is placed on the usage of the Copernicus Marine Client module in this tutorial; a comprehensive explanation of this library is provided in Section [3. Data downloading with Coprnicus Marine Client](#Data_downloading).\n",
    "\n",
    "\n",
    "### Used Datasets\n",
    "\n",
    "The Copernicus service offers a wide variety of oceanographic data that can be used for a multitude of purposes. The most basic way to access the different products is through the Copernicus website. However, there are various access methods that allow for the automation of data downloads, avoiding the need to go through the website.\n",
    "\n",
    "The available products include observational, remote sensing, modeling, and ocean indicators data. Each type of data has its own characteristics such as data availability at depth or only at the surface, spatial and temporal resolution, available variables (physical, biogeochemical), frequency of database updates, etc.\n",
    "\n",
    "In this tutorial, we will use modeling data as they are among the most accessible providing 3D grided data that can be used for a variety of pourposes. Aditionally we will use the data of an Ocean Monitoring Indicator (OMI) computed by Copernicus services to provide an indicator of ENSO.\n",
    "\n",
    "Below it is shown the identifier of the Copernicus product that will be used in this tutorial:\n",
    "\n",
    "* **Global Physics Reanalysis:** [GLOBAL_MULTIYEAR_PHY_001_030](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description)\n",
    "* **NINO34 index:** [GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomalies](https://data.marine.copernicus.eu/product/GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomalies/description)\n",
    "\n",
    "All datasets used in this tutorial will be described in detail in the corresponding section when they are used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e591cce-78b9-4a6b-b98a-f5447ec99716",
   "metadata": {},
   "source": [
    "<a id=\"Plot_NINO_index\"></a>\n",
    "# <span style=\"color: #22689B;\">**2. Plot NINO3.4 index**</span>\n",
    "\n",
    "\n",
    "As explained in the [Introduction](#Introduction), the Southern Oscillation is typically characterized using various indicators. The Copernicus product [GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomalies](https://data.marine.copernicus.eu/product/GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomalies/description) is designed to offer an Ocean Monitoring Indicator (OMI) that provides information about the ENSO phase. This product is an indicator of the state of the central tropical Pacific el Niño conditions. It provides the sub-surface temperature anomalies on average over the standard NINO 3.4 area (170°W - 120°W, 5°S – 5°).\n",
    "\n",
    "\n",
    "<p><img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"img/GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomaly-hq_med.png\" alt=\"\" /></p>\n",
    "<p style=\"text-align: center;\"><em><a href=\"https://data.marine.copernicus.eu/product/GLOBAL_OMI_CLIMVAR_enso_sst_area_averaged_anomalies/description\">Image of Copernicus OMI product Nino 3.4 Sea Surface Temperature time series from Reanalysis</a></em></p>\n",
    "\n",
    "According to the definition of the NINO3.4 index, positive values of the indicator are associated with warm anomalies in the NINO 3.4 region (El Niño conditions), while negative values are linked to cool sea temperatures in the region (La Niña phase of the ENSO).\n",
    "\n",
    "In this section, we will carry out a simple initial exercise. Here, we will learn how to access a Copernicus data file to create a chart of the NINO3.4 OMI similar to the one displayed on the Copernicus Marine Datastore website. However, since in this tutorial, we will be working with annual data, we will refine the chart to display the annual mean indicator data together.\n",
    "\n",
    "In this first exercise, we will focus on working with the netCDF files provided by the Copernicus Data Store. Therefore, the required dataset has already been previously downloaded and stored in the data directory of the tutorial. The various procedures to access the Copernicus databases will be explained in a later section.\n",
    "\n",
    "The first step to work with Copernicus data is to open the corresponding data file. All the Copernicus Marine Service products are distibuted in the **NetCDF format**, which is a common way of storing scientific data. There are a variety of tools to work with netCDF files; in this tutorial, we will use Python for accessing, processing, and plotting data.\n",
    "\n",
    "The [xarray](http://xarray.pydata.org/en/stable/) library provides a variety of Python functions and procedures to access and work with data stored in netCDF files. Throughout this tutorial, we will refer to this library using the abbreviation `xr.`\n",
    "\n",
    "The code in the following cell uses the [open_dataset](https://docs.xarray.dev/en/stable/generated/xarray.open_dataset.html) function to open the file previously downloaded (`DataFileName`). On this example, the function creates a variable (`DataNINO`) that will be used from now on to access the data in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842fcba-fc3f-422c-af1b-7be986e871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open nino Dataset\n",
    "\n",
    "DataFileName_nino = 'data/global_omi_climate-variability_nino34_sst_anom_19930115_P20220427_R19932014.nc'\n",
    "\n",
    "# Open the datafile\n",
    "DataNINO = xr.open_dataset(DataFileName_nino)\n",
    "\n",
    "# Show info of dataset\n",
    "DataNINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a108397-9f22-4030-9ee6-b48aa411360d",
   "metadata": {},
   "source": [
    "As you can see in th output of the previous cell, NetCDF files contain three different objects:\n",
    "\n",
    "* **Variables**: Multidimensional arrays of data.\n",
    "* **Dimensions & Coordinates**: Special 1D variables used to define the dimensions of each variable.\n",
    "* **Attributes**: Labels that can be attached to any variable or the dataset (global attributes).\n",
    "\n",
    "You can explore these objects by clicking on the icons (paper and hard drive) located to the right of each object.\n",
    "\n",
    "A large number of oceanic indicators provided by the Copernicus Service are offered with a multi-product approach. This means that the same indicator can be calculated from different Copernicus products, allowing for an estimation of the uncertainty of the results.\n",
    "\n",
    "It can be observed that the database in our example contains a list of variables, all of which start with sst_*. This is because it is a multi-product OMI that is calculated from a group of global reanalyses. In the data file, there is a variable that stores OMI data computed with various systems, including GLORYS2V4 (sst_glor), C-GLORS (sst_cglo), ORAS5 (sst_oras), and FOAM (sst_foam). Additionally, two special variables, sst_mean and sst_std, are present, containing the ensemble mean and ensemble standard deviation data, respectively.\n",
    "\n",
    "In the following cell, a function called `PlotTS` is defined, which allows plotting a time series graph of the OMI data. Since the used product is a multi-product, uncertainty data for different components of the OMI are also available. Therefore, we leverage this information to include the uncertainty band in the graph.\n",
    "\n",
    "To facilitate understanding, the function is divided into three separate sections:\n",
    "\n",
    "1. <u>**Figure creation:**</u> This section includes the necessary commands to create a figure object and associate it with the graph axes.\n",
    "\n",
    "1. <u>**Plot Time Series:**</u> In this section, we use the [.plot()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) and [.fill_between()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.fill_between.html) functions to generate the solid line (representing mean data) and the shaded area (corresponding to uncertainties), respectively.\n",
    "\n",
    "1. <u>**Figure Formsating:**</u> The figure is finalized by including additional editing commands, such as formatting the temporal X-axis or adding a title.\n",
    "\n",
    "The last line of the cell calls the PlotTS function, including among the call parameters the data series to be plotted. As shown in the line, access to this data can be done using the name used to open the `DataNINO` dataset and the name of the variable you want to access. In the example's case, the required elements are the dates (`time`), the mean values of the indicator (`sst_mean`), and the standard deviation values (`sst_std`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a25e1-8b68-44b3-a046-c65b6ccb211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a chart of the time series for the NINO34 index.\n",
    "\n",
    "def PlotTS(DataX, DataY, Spread):\n",
    "    '''\n",
    "        Create a chart with time axis, including spread of data.\n",
    "    '''\n",
    "    \n",
    "    import matplotlib.dates as mdt                     # Matplot library for date managing\n",
    "    \n",
    "    #1. Figure Creation\n",
    "    Fig = plt.figure(figsize=(15,7))                   # Create new figure\n",
    "    Ax = plt.axes()                                    # Create axes\n",
    "    \n",
    "    #2. Plot Time Series\n",
    "    plt.plot(DataX, DataY, label = 'Mean', zorder=2)   # Plot solid line (mean)\n",
    "    \n",
    "    # Plot Spread\n",
    "    Min = DataY - Spread * 2\n",
    "    Max = DataY + Spread * 2\n",
    "    plt.fill_between(DataX, Min, Max,                  # Shaded interval (spread)\n",
    "                     alpha=0.5,\n",
    "                     facecolor= '0.4',\n",
    "                     linewidth=0,\n",
    "                     antialiased=True,\n",
    "                     label = 'Spread', zorder=1)\n",
    "\n",
    "    #3. Figure Format\n",
    "    Ax.axhline(y=0, color='0.5', linewidth = 0.5)      # Add a grey line at Y=0\n",
    "    \n",
    "    Yr = mdt.YearLocator()\n",
    "    Ax.xaxis.set_major_locator(Yr)                     # Define years for mayor ticks\n",
    "    \n",
    "    YrFmt = mdt.DateFormatter('%y')\n",
    "    Ax.xaxis.set_major_formatter(YrFmt)                # Format labels in X-axis ticks\n",
    "    \n",
    "    Mth = mdt.MonthLocator()\n",
    "    Ax.xaxis.set_minor_locator(Mth)                    # Define months for minor ticks\n",
    "\n",
    "    plt.ylabel('[ºC]')                                 # Add label to Y-axis\n",
    "    plt.xlabel('Yr')                                   # Add label to X-axis\n",
    "    plt.title('NINO3.4 Index')                         # Add a title\n",
    "    plt.grid(axis='x', linestyle=':')                  # Show grid on X-axis\n",
    "    \n",
    "    Ax.legend()                                        # Show legend\n",
    "    \n",
    "    return Fig, Ax\n",
    "\n",
    "# Calling the function to make the plot\n",
    "PlotTS(DataNINO['time'], DataNINO['sst_mean'], DataNINO['sst_std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68567212-ba65-4153-8f62-e75a1ebff32f",
   "metadata": {},
   "source": [
    "The result of the previous cell displays a graph of the OMI similar to the one provided in the Copernicus Data Store but with an additional shaded area corresponding to the uncertainty of the data. It can be observed that, in general, the level of agreement among the different products used for the OMI is quite high, so the uncertainty values are relatively small compared to the range of variability of the indicator.\n",
    "\n",
    "The graph shown above displays the results of data calculated in monthly averages. However, throughout this tutorial, we will be interested in analyzing data on an annual basis. Therefore, it is interesting to modify the previous graph to also show the data of the NINO34 indicator as annual averages.\n",
    "\n",
    "The following cell defines a new function `PlotTS2`, which leverages the old function `PlotTS`, modifying it to display the data of annual averages of the indicator in the form of bars. For this purpose, the [.bar()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) function from [matplotlib](https://matplotlib.org/) is used. As before, the function has been divided into the following four sections:\n",
    "\n",
    "1. <u>**Create the base plot:**</u> Utilizes the `PlotTS` function to create the base graph.\n",
    "1. <u>**Compute Annual Mean:**</u> In a single line, the [.groupby()](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.groupby.html) and [.mean()](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.mean.html) functions from [xarray](http://xarray.pydata.org/en/stable/) are used to generate a new variable `AnnualMean` containing the annual mean data.\n",
    "1. <u>**Format Time Values:**</u> The dates (years) generated from the calculation of annual means need to be formatted for plotting functions to understand them. To achieve this, we use the [.Timestamp()](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html) and [.date_range()](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html) functions from [Pandas](https://pandas.pydata.org/docs/) to generate a variable `Time` containing the date data centered on the central day of each year.\n",
    "1. <u>**Plot Bar Chart:**</u> Finally, bar charts are overlaid using the [.bar()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) function from [matplotlib](https://matplotlib.org/). Note that a different color is used for positive (`orange`) and negative (`olive`) data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb331b-d797-454f-99c8-6b7e4d6a2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add annual mean to the plot\n",
    "\n",
    "def PlotTS2(DataX, DataY, Spread):\n",
    "    #Create a plot with Plot TS including annual averages.\n",
    "    \n",
    "    #1. Create the base plot\n",
    "    Fig, Ax = PlotTS(DataX, DataY, Spread)\n",
    "    \n",
    "    #2. Compute Annual Mean\n",
    "    AnnualMean = DataY.groupby('time.year').mean('time')\n",
    "    \n",
    "    #3. Format Time Values\n",
    "    DateIni = pd.Timestamp(AnnualMean['year'].values[0], 6, 1)\n",
    "    LengthTime = len(AnnualMean['year'])\n",
    "    Time = pd.date_range(DateIni, periods = LengthTime, freq = '12M')\n",
    "    \n",
    "    #4. Plot Bar Chart\n",
    "    plt.bar(Time, AnnualMean, width=300, zorder=0, color='orange')\n",
    "    \n",
    "    SelI = np.where(AnnualMean < 0)\n",
    "    plt.bar(Time[SelI], AnnualMean[SelI], width=300, zorder=0, color='olive')\n",
    "    \n",
    "    return AnnualMean\n",
    "\n",
    "AnnualMeanNINO = PlotTS2(DataNINO['time'],\n",
    "                         DataNINO['sst_mean'],\n",
    "                         DataNINO['sst_std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07d807-af01-4933-b727-793ab2d2eda6",
   "metadata": {},
   "source": [
    "As a result, we can state that the years 1997 and 2015 exhibited a distinct prevalence of El Niño conditions, while the years 1999 and 2011 were affected by a particular influence of La Niña conditions.\n",
    "\n",
    "***\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<h3>Exercises to explore:</h3>\n",
    "\n",
    "* Modify the previous code toplot the NINO34 of diferent Copernicus products.\n",
    "\n",
    "This exercise can be carried out by replacing the variable `sst_mean` with the variable corresponding to any other system within the database (`sst_glor`, `sst_cglo`, `sst_oras`, or `sst_foam`) when calling the plotting function `PlotTS` or `PlotTS2`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae52fb6-4c18-4749-aeaa-118199e974f2",
   "metadata": {},
   "source": [
    "<a id=\"Data_downloading\"></a>\n",
    "# <span style=\"color: #22689B;\">**3. Data downloading with Copernicus Marine Client**</span>\n",
    "\n",
    "For the following exercises, we will work with the Copernicus Marine global reanalysis product. This will allow us to perform a spatial analysis of the temperature variability and patterns associated with El Niño and La Niña in Southeast Asia and parts of Oceania.\n",
    "\n",
    "However, unlike the previous example, before we begin working, we need to download the Copernicus database we will be using, as it is not previously downloaded. Below are the basic specifications of the data that will be used in the subsequent exercises of the tutorial:\n",
    "\n",
    "|  |  |\n",
    "| :---: | :---|\n",
    "| **Copernicus product** | [GLOBAL_MULTIYEAR_PHY_001_030](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description) |\n",
    "| **Dataset** | cmems_mod_glo_phy_my_0.083deg_P1M-m |\n",
    "| **Variables** | Sea Surface Temperature (thetao), Sea Surface Height (zos), and Mixed Layer Thickness (mlotst) |\n",
    "| **Dates** | Full record since 1993-02-01 up to the last available date. |\n",
    "| **Latitudes** | From 15º South to 30º North |\n",
    "| **Longitudes** | From 80º East to 160º East |\n",
    "\n",
    "While it is possible to download these data from the Copernicus Data Store website, there is a limitation on the data size that can be requested through this method. Therefore, we will explain how to download the tutorial data using the Python library **copernicus_data_store**.\n",
    "\n",
    "The installation of the `copernicus_marine_client` library should be performed as a maintenance task within the Python environment being used. There are support pages in the [Copernicus Help Center](https://help.marine.copernicus.eu/en/articles/7970514-copernicus-marine-toolbox-installation) website that assist users in installing this library. In this tutorial, we won't delve into this task; however, we include the file CopernicusWorkshop_PythonEnv.yml in the tutorial, which can be used to create an Anaconda or Mamba environment that includes the necessary libraries to run this tutorial.\n",
    "\n",
    "One of the procedures that the [copernicus_marine_client](https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction) library provides is opening a session in the Copernicus Datastore system. To do this, the [.login()](https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction#h_9172b5c79a) function of the library should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a15219-fa34-4a00-9a40-d5b6d94c81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Platform login\n",
    "\n",
    "cmc.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c10d89-5843-45d7-90f7-2200a52d2096",
   "metadata": {},
   "source": [
    "This function opens a session in the Copernicus Marine Datastore, allowing data to be freely downloaded from this point onward.\n",
    "\n",
    "Once the session is open, it is possible to download data using the [.subset()](https://help.marine.copernicus.eu/en/articles/7972861-copernicus-marine-toolbox-cli-subset) function of the library. This function allows downloading data by selecting multiple parameters such as the Copernicus product, latitude and longitude range, variables, date range, and depth range.\n",
    "\n",
    "The configuration of the [.subset()](https://help.marine.copernicus.eu/en/articles/7972861-copernicus-marine-toolbox-cli-subset) function parameters strongly depends on the Copernicus product you wish to download. However, the [Copernicus Data Store](https://data.marine.copernicus.eu/products) website offers the option to copy the download function's configuration.\n",
    "\n",
    "<p><img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"img/CopernicusMarineClient_config_2.gif\" alt=\"\" /></p>\n",
    "\n",
    "The following cell makes a data request that will download the necessary data for this tutorial. As can be seen, the function's configuration parameters include the information needed to:\n",
    "* Select the corresponding Copernicus product: `dataset_id`\n",
    "* Choose the desired list of variables: `variables`\n",
    "* Specify the desired geographic window: `minimum_longitude`, `maximum_longitude`, `minimum_latitude`, and `maximum_latitude`\n",
    "* Set the desired date range: `start_datetime`, `end_datetime`\n",
    "* Define the desired depth range: `minimum_depth`, `maximum_depth`\n",
    "* Specify the downloaded file's name and storage directory: `output_filename`, `output_directory`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2f91b-a841-4e2d-9e42-9787b5cb19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download GLO-MY\n",
    "\n",
    "DataPath = 'data'\n",
    "DataFile = 'CMEMS_GLO-REA.nc'\n",
    "\n",
    "LatMin = -15\n",
    "LatMax = 30\n",
    "LonMin = 80\n",
    "LonMax = 160\n",
    "\n",
    "cmc.subset(dataset_id = 'cmems_mod_glo_phy_my_0.083deg_P1M-m',  # Copernicus dataset\n",
    "           variables = ['thetao', 'zos', 'mlotst'],             # List of variables to download\n",
    "           minimum_longitude = LonMin,                          # Minimum latitude\n",
    "           maximum_longitude = LonMax,                          # Maximum latitude\n",
    "           minimum_latitude = LatMin,                           # Minimum longitude\n",
    "           maximum_latitude = LatMax,                           # Maximum longitude\n",
    "           start_datetime = '1993-02-01T00:00:00',              # Start date\n",
    "           #end_datetime = '2021-06-01T00:00:00',               # End date\n",
    "           minimum_depth = 0,                                   # Minimum depth\n",
    "           maximum_depth = 0,                                   # Maximum depth\n",
    "           output_filename = DataFile,                          # Output file name\n",
    "           output_directory = DataPath)                         # Output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d2605-e514-4847-a943-6feebcb6f267",
   "metadata": {},
   "source": [
    "As can be seen in the previous cell, as we are interested in downloading all data after February 1st, 1993, the parameter `end_datetime` can be removed so that the system downloads all data up to the latest date abailable.\n",
    "\n",
    "Once the data has been successfully downloaded, we have the corresponding netCDF file stored on our system, and we can start working with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f3cd9-3051-49c6-91ba-229ac352cad4",
   "metadata": {},
   "source": [
    "<a id=\"Maps_of_anomalies\"></a>\n",
    "# <span style=\"color: #22689B;\">**4. Plotting maps of anomalies**</span>\n",
    "\n",
    "One of the ways in which it is possible to observe oceanic patterns resulting from the El Niño Southern Oscillation (ENSO) is by plotting maps of sea surface temperature anomalies. However, it is well-known that ENSO has implications for various oceanographic variables and teleconnections with oceanic and atmospheric variability in very distant regions.\n",
    "\n",
    "In this exercise, we will learn how to access Copernicus data to display the effect of ENSO on three variables: sea surface temperature (`thetao`), sea level (`zos`), and mixed layer depth (`motst`). This analysis will be conducted by plotting annual anomaly maps of the different variables in those years where we know there was a strong influence of El Niño or La Niña patterns.\n",
    "\n",
    "Since our goal is to be able to plot annual anomaly maps, the first step to get started is to open the data file and calculate both the annual mean and the overall mean of the data. In the following cell, we perform these tasks using the same functions we used in Section 2. [Plot NINO3.4 index](#Plot_NINO_index): `open_dataset`, `mean`, and `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a717a0-e15c-47c0-ba78-694d0838a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open Dataset\n",
    "\n",
    "DataFileName = 'data/CMEMS_GLO-REA.nc'\n",
    "\n",
    "# Open the datafile\n",
    "DS = xr.open_dataset(DataFileName)\n",
    "\n",
    "# Compute climatic mean\n",
    "MeanDS = DS.mean('time')\n",
    "\n",
    "# Compute annual mean\n",
    "AnnualMeanDS = DS.groupby('time.year').mean('time')\n",
    "\n",
    "# Show info of Annual Mean\n",
    "AnnualMeanDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004c50d-caaf-4097-8df7-822c903b096e",
   "metadata": {},
   "source": [
    "Once annual and climatic means have been calculated, we can focus on computing the anomalies for a specific variable in specific years.\n",
    "\n",
    "The following cell is dedicated to calculating the anomalies of a variable (`VarName`) for various specific years (`YrList`). The code within generates a data dictionary (`AnomDataDict`) in which the anomaly data is stored.\n",
    "\n",
    "The process of calculating anomalies for each year occurs in two distinct steps. Initially, it is necessary to select the data corresponding to the chosen year and store it in the variable SelData. To do so, we use the function [.sel()](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.sel.html) function of xarray. Subsequently, the anomalies are computed and stored in the DataDict dictionary associated with the label of the year (`Yr`).\n",
    "\n",
    "In this example, the years 1999 and 2015 have been chosen for representation since, as can be observed in the graph of the NINO34 index plotted in Section 2 ([Plot NINO3.4 index](#Plot_NINO_index)), they are dominated by La Niña and El Niño conditions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7bab7-eb1a-427e-8505-8080ba375ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select date and variable\n",
    "\n",
    "#VarName = 'thetao'\n",
    "#VarName = 'zos'\n",
    "VarName = 'mlotst'\n",
    "\n",
    "YrList = [1999, 2015]\n",
    "\n",
    "AnomDataDict = {}\n",
    "for Yr in YrList:\n",
    "    # Subseting a especific date and variable from the dataset DS\n",
    "    SelData = AnnualMeanDS[VarName].sel(year = Yr, method = 'nearest')\n",
    "    \n",
    "    #Compute anomaly\n",
    "    AnomDataDict[Yr] = (SelData - MeanDS[VarName]).squeeze()\n",
    "    \n",
    "AnomDataDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdf627-8bd7-4979-b569-5368434734e3",
   "metadata": {},
   "source": [
    "In the following cell, we define a new function (`PlotAnomMap`) that is responsible for plotting a map of a data matrix (`Data`). The function is also designed to adjust the color scale of the data so that positive and negative values are represented in different intensities of red or blue, respectively, and values close to zero are represented in white. This color scale is very convenient for anomaly analysis as it allows easy distinction between regions affected by positive or negative anomalies.\n",
    "\n",
    "As in previous occasions, the structure of the function has been organized into four separate sections to facilitate understanding:\n",
    "\n",
    "1. <u>**Figure creation:**</u> This section encompasses the essential commands for creating a `figure` object and linking it with the map axes, which, being the axes of a map, must be defined with a specific cartographic projection.\n",
    "\n",
    "1. <u>**Editing basic map features:**</u> This section comprises a series of commands to define various aesthetic features of the map, including the coastline, latitude and longitude gridlines, land mask, country borders, and map lat/lon limits.\n",
    "\n",
    "1. <u>**Command to plot the data:**</u> In this case, we will utilize the [pcolor](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pcolor.html) function, generating a pseudocolor plot of the data. The arguments of this function must be provided in the following order: longitude, latitude, and Z values. The `cmap` argument is chosen to produce a blue-white-red color scale. Additionally, the color scale limits are obtained and stored in the variable `CMapLim`.\n",
    "\n",
    "1. <u>**Final editing commands:**</u> The figure is completed by incorporating additional editing commands, such as the inclusion of a formatted title and the color scale of the plot or the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59263fc0-9526-485c-9493-95ba9964cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Map of annomalies\n",
    "\n",
    "def PlotAnomMap(Data, Title, Units):\n",
    "    '''\n",
    "    This function compiles the code needed to plot a map\n",
    "    '''\n",
    "    \n",
    "    #1. Figure Creation\n",
    "    Fig = plt.figure(figsize=(15, 5))                                          # create new figure\n",
    "    Ax = plt.axes(projection=ccrs.PlateCarree())                               # create axes with the map projection\n",
    "    \n",
    "    #2. Editing basic map features\n",
    "    Ax.coastlines()                                                            # add the coastlines\n",
    "    Gl = Ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)                # add the longitude / latitude lines\n",
    "    Gl.right_labels = False                                                    # remove latitude labels on the right\n",
    "    Gl.top_labels = False                                                      # remove longitude labels on the top\n",
    "    Ax.add_feature(cfeature.LAND, zorder=1, edgecolor='k')                     # add land mask\n",
    "    Ax.add_feature(cfeature.BORDERS, linestyle=':')                            # add\n",
    "    Ax.set_extent([LonMin, LonMax, LatMin, LatMax],crs=ccrs.PlateCarree())     # define the extent of the map [lon_min,lon_max,lat_min,lat_max]\n",
    "    \n",
    "    \n",
    "    #3. Command to plot data\n",
    "    CMapLim = min(abs(Data.min(dim=None)), Data.max(dim=None))                 # define limits of color scale\n",
    "\n",
    "    Map = Ax.pcolor(Data['longitude'],                                         # Longitude data\n",
    "                    Data['latitude'],                                          # Latitude data\n",
    "                    Data,                                                      # Values to plot\n",
    "                    vmin= -CMapLim, vmax=CMapLim,                              # define limits of color scale\n",
    "                    cmap='RdBu_r')                                             # Define colormap\n",
    "\n",
    "    #4. Final editing commands\n",
    "    Ax.set_title(Title, fontsize=15, fontweight=\"bold\")                        # add a title to the figure\n",
    "    CBar = plt.colorbar(Map, ax=Ax, label=Units)                               # add the colorbar\n",
    "    return\n",
    "\n",
    "# Loop to plot maps for any dataset stored in AnomDataDict\n",
    "for Yr, AnomData2Map in AnomDataDict.items():\n",
    "    MapTitle = 'Variable: {}; Year: {}'.format(VarName, Yr)\n",
    "    PlotAnomMap(AnomData2Map, MapTitle, DS[VarName].units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ef809-4430-4f7a-9128-ada731bbdd85",
   "metadata": {},
   "source": [
    "In the resulting maps, we can observe a markedly different distribution of anomalies for the years 1999 and 2015. We can see that the sea surface temperature in the Gulf of Bengal and the South China Sea is clearly positive in the year 2015 (a year dominated by El Niño conditions), while in the year 1999 (a year dominated by the La Niña pattern), the anomalies of sea surface temperature are negative.\n",
    "\n",
    "However, our results do not align with expectations around New Guinea. According to theory, we should expect warmer anomalies in this region in a year dominated by the La Niña phase (1999). These differences arise because, in reality, we are studying specific years influenced by the interannual variability of multiple processes that can deviate the results from what is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca8b51-c2e4-4c14-8019-1bad804aab56",
   "metadata": {},
   "source": [
    "<a id=\"Plottingpatterns\"></a>\n",
    "# <span style=\"color: #22689B;\">**5. Plotting El Niño and La Niña patterns**</span>\n",
    "\n",
    "The results shown in the previous section were obtained for specific years, and as such, they may be influenced by the inherent interannual variability of the data. To prevent the interannual variability of the data from compromising the reliability of the results, in this section, we will learn how to select data for specific date ranges. This will allow us to utilize the plotting functions developed in the previous section to create a map of averaged anomalies for the years influenced by the El Niño and La Niña phases.\n",
    "\n",
    "In the next cell, we use the [.where()](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function from numpy to identify values of the NINO34 index that are greater than and less than zero. In this way, two new variables are obtained that contain the list of years characterized by a dominance of the El Niño pattern (`YrPos`) or La Niña pattern (`YrNeg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f997d-14a2-4379-98c0-01e21cd77638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select years of positive and negative NINO3.4 index and compute averages\n",
    "\n",
    "PosNINO = np.where(AnnualMeanNINO > 0)\n",
    "YrPos = AnnualMeanNINO['year'][PosNINO]\n",
    "\n",
    "NegNINO = np.where(AnnualMeanNINO < 0)\n",
    "YrNeg = AnnualMeanNINO['year'][NegNINO]\n",
    "\n",
    "display(YrPos)\n",
    "display(YrNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab4f86-53fe-49c2-a704-90182787af59",
   "metadata": {},
   "source": [
    "In this way, we can use the obtained lists of years to calculate the composite fields of a variable averaged exclusively for the desired years.\n",
    "\n",
    "In the following cell, a combination of the .sel() and .mean() functions from xarray is used to obtain an averaged field of a variable (`VarName`) for the sequence of years dominated by the El Niño pattern (`YrPos`) or La Niña pattern (`YrNeg`). This calculation is performed twice, storing the results in the variables `MeanPos` and `MeanNeg`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52b840-ee74-4e5f-ab11-6295c46d794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute averages and anomalies\n",
    "\n",
    "MeanPos = AnnualMeanDS[VarName].sel(year = YrPos, method = 'nearest').mean('year') # Compute mean field averaged on especific years\n",
    "#AnomPos = (MeanPos - MeanDS[VarName]).squeeze()                                    # Compute anomalies of the averaged field\n",
    "\n",
    "MeanNeg = AnnualMeanDS[VarName].sel(year = YrNeg, method = 'nearest').mean('year') # Compute mean field averaged on especific years\n",
    "#AnomNeg = (MeanNeg - MeanDS[VarName]).squeeze()                                    # Compute anomalies of the averaged field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b92cda-487d-4651-be0c-af49461712a3",
   "metadata": {},
   "source": [
    "Next, we use the `PlotAnomMaps` function defined earlier to visualize the results. However, since we desire to plot anomaly maps, it is necessary to calculate these from the data generated in the previous cell. To do this, we subtract the climatic mean (`MeanDS`) from the averaged field (`MeanPos` or `MeanNeg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f2106-4bf1-4c20-b969-9b9582f4c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "\n",
    "MapTitle = 'Variable: {}; Positive NINO3.4'.format(VarName)\n",
    "AnomPos = (MeanPos - MeanDS[VarName]).squeeze()              # Compute anomalies of the averaged field\n",
    "PlotAnomMap(AnomPos, MapTitle, DS[VarName].units)\n",
    "\n",
    "MapTitle = 'Variable: {}; Negative NINO3.4'.format(VarName)\n",
    "AnomNeg = (MeanNeg - MeanDS[VarName]).squeeze()              # Compute anomalies of the averaged field\n",
    "PlotAnomMap(AnomNeg, MapTitle, DS[VarName].units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bddf5a-72ec-4640-9a5f-65a241145b2b",
   "metadata": {},
   "source": [
    "In this way, we obtain more consistent results with what is expected since we are analyzing maps of anomalies averaged over a series of years dominated by one pattern or another. Thus, we observe that in years dominated by the La Niña pattern, warm anomalies are observed around New Guinea and cold anomalies in the Gulf of Bengal. However, in years dominated by the El Niño pattern, these anomalies are reversed.\n",
    "\n",
    "***\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<h3>Exercises to explore:</h3>\n",
    "\n",
    "* Modify the previous code to analyze the effect of El Niño and La Niña phases on the Sea Surface High (`thetao`) and Mixed Layer Thickness (`mlotst`) variables.\n",
    "\n",
    "    \n",
    "</div>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b84b12-0f1e-4801-bf44-c3e3c4bd69a5",
   "metadata": {},
   "source": [
    "# <span style=\"color: #22689B;\">**5. Conclusions**</span>\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Congratulations!</b> You have successfully completed the introductory-intermediate tutorial on using and visualizing Copernicus Marine Reanalysis Products. Throughout this tutorial, we have explained the basic tools necessary to access and visualize gridded Copernicus Marine data.\n",
    "<br><br>\n",
    "In this tutorial, you acquired all the information you need to:\n",
    "\n",
    "* Download Copernicus Marine products using the web service.\n",
    "* Download Copernicus Marine products using copernicus_marine_client.\n",
    "* Access NetCDF datasets.\n",
    "* Navigate through the different variables, dimensions and attributes of a NetCDF file.\n",
    "* Select data subsets within a NetCDF file.\n",
    "* Compute temporal means of netCDF files.\n",
    "* Plot anomaly maps of any variable.\n",
    "* Plot maps of temporal averages.\n",
    "* Plot time series of data.\n",
    "\n",
    "We sincerely hope that you have enjoyed the tutorial and found useful information in it. Please keep in mind that the tutorial has a progressive difficulty, moving quickly from basic elements to intermediate levels. Our intention is for all users to find useful information tailored to their level.\n",
    "\n",
    "We understand that, for a user without prior knowledge, fully understanding all the procedures in the tutorial may be a challenge that requires some effort. However, we encourage everyone to take on the challenge as this is just the beginning of a journey towards a new understanding of the ocean and its ecosystems.\n",
    "\n",
    "The final exercise proposed in this tutorial is designed for students to put into practice all the knowledge acquired throughout the course. We recommend that less advanced users approach it constructively and with awareness of their own limitations.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMEMS v3",
   "language": "python",
   "name": "cmems_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
